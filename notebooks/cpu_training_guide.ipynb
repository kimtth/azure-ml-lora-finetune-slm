{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c4135c8",
   "metadata": {},
   "source": [
    "# CPU-Optimized LoRA Fine-tuning Guide\n",
    "\n",
    "This notebook demonstrates how to fine-tune Phi-4-mini-instruct using LoRA on **CPU-only Azure ML compute** when GPU access is restricted.\n",
    "\n",
    "## Available CPU VMs\n",
    "\n",
    "| VM | Cores | RAM | Storage | Cost/hr | Best For |\n",
    "|----|-------|-----|---------|---------|----------|\n",
    "| **Standard_E4ds_v4** âœ… | 4 | 32GB | 150GB | $0.29 | **Training (Recommended)** |\n",
    "| Standard_DS3_v2 | 4 | 14GB | 28GB | - | Small tests only |\n",
    "| Standard_DS11_v2 | 2 | 14GB | 28GB | - | Development only |\n",
    "\n",
    "**Recommendation:** Use **Standard_E4ds_v4** for actual training due to 32GB RAM.\n",
    "\n",
    "## Key Optimizations\n",
    "\n",
    "- âœ… No quantization (CPU doesn't support 4-bit)\n",
    "- âœ… Smaller LoRA rank (8 vs 16)\n",
    "- âœ… Reduced batch size (1) with gradient accumulation (16)\n",
    "- âœ… Limited dataset (1000 samples vs 15K)\n",
    "- âœ… Shorter sequences (256 vs 512 tokens)\n",
    "- âœ… 2 data loading workers for parallel processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bd0f83",
   "metadata": {},
   "source": [
    "## 1. Configuration Comparison: GPU vs CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89f4cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Configuration comparison\n",
    "config_comparison = {\n",
    "    'Setting': ['Compute', 'LoRA Rank', 'LoRA Alpha', 'Batch Size', 'Gradient Accumulation', \n",
    "                'Effective Batch', 'Max Seq Length', 'Dataset Samples', 'Quantization', \n",
    "                'Training Time', 'Memory Usage', 'Cost per Run'],\n",
    "    'GPU (Standard_NC6s_v3)': ['V100 GPU', '16', '32', '4', '4', '16', '512', '15,000', \n",
    "                               '4-bit', '1-2 hours', '~5GB GPU', '$0.90-$1.80'],\n",
    "    'CPU (Standard_E4ds_v4)': ['4 cores, 32GB', '8', '16', '1', '16', '16', '256', '1,000', \n",
    "                               'None', '2-4 hours', '~16GB RAM', '$0.58-$1.16']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(config_comparison)\n",
    "print(\"GPU vs CPU Configuration Comparison:\")\n",
    "print(\"=\" * 100)\n",
    "print(df.to_string(index=False))\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5262fee4",
   "metadata": {},
   "source": [
    "## 2. Submit CPU Training Job to Azure ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6d0e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit CPU training job - easiest method\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "print(\"Submitting CPU training job to Azure ML...\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Using Standard_E4ds_v4: 4 cores, 32GB RAM, $0.29/hr\")\n",
    "print(\"Training 1000 samples from Databricks Dolly 15K dataset\")\n",
    "print(\"Expected time: 2-4 hours\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Run the submission script\n",
    "result = subprocess.run(\n",
    "    [sys.executable, \"../jobs/submit_training_job_cpu.py\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "print(result.stdout)\n",
    "if result.returncode != 0:\n",
    "    print(\"Error:\", result.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693b2df8",
   "metadata": {},
   "source": [
    "## 3. Local CPU Training (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af1e8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training locally on CPU (for testing only)\n",
    "# WARNING: This will download model (~7GB) and take 2-4 hours\n",
    "\n",
    "train_locally = False  # Set to True to actually run\n",
    "\n",
    "if train_locally:\n",
    "    import subprocess\n",
    "    import sys\n",
    "    \n",
    "    print(\"Starting local CPU training...\")\n",
    "    print(\"This will take 2-4 hours. Monitor progress below.\")\n",
    "    \n",
    "    result = subprocess.run([\n",
    "        sys.executable, \"../src/train_cpu.py\",\n",
    "        \"--output_dir\", \"./outputs_cpu_local\",\n",
    "        \"--max_samples\", \"100\",  # Small subset for testing\n",
    "        \"--num_epochs\", \"1\"\n",
    "    ])\n",
    "else:\n",
    "    print(\"Local training disabled. Set train_locally=True to run.\")\n",
    "    print(\"For production training, use Azure ML (previous cell).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bc81e1",
   "metadata": {},
   "source": [
    "## 4. Cost Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfe9de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost comparison for training runs\n",
    "\n",
    "cost_data = {\n",
    "    'VM Type': ['Standard_E4ds_v4 (CPU)', 'Standard_NC6s_v3 (GPU)'],\n",
    "    'Cost per Hour': ['$0.29', '$0.90'],\n",
    "    'Training Time (1K samples)': ['2-4 hours', 'N/A'],\n",
    "    'Training Time (15K samples)': ['N/A (too slow)', '1-2 hours'],\n",
    "    'Cost per Run (1K)': ['$0.58 - $1.16', 'N/A'],\n",
    "    'Cost per Run (15K)': ['Not recommended', '$0.90 - $1.80']\n",
    "}\n",
    "\n",
    "df_cost = pd.DataFrame(cost_data)\n",
    "print(\"Cost Comparison:\")\n",
    "print(\"=\" * 80)\n",
    "print(df_cost.to_string(index=False))\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nðŸ’¡ Tip: CPU is cost-effective for small datasets (1K samples)\")\n",
    "print(\"ðŸ’¡ Tip: For 15K samples, GPU is faster and more cost-efficient\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75531919",
   "metadata": {},
   "source": [
    "## 5. View CPU Training Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f4a73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "# Load CPU configuration\n",
    "with open('../config/training_config_cpu.yaml', 'r') as f:\n",
    "    cpu_config = yaml.safe_load(f)\n",
    "\n",
    "print(\"CPU Training Configuration:\")\n",
    "print(\"=\" * 80)\n",
    "print(yaml.dump(cpu_config, default_flow_style=False))\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66cdf4bf",
   "metadata": {},
   "source": [
    "## 6. Memory and Performance Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60031600",
   "metadata": {},
   "outputs": [],
   "source": [
    "tips = {\n",
    "    'Issue': [\n",
    "        'Out of Memory',\n",
    "        'Training Too Slow',\n",
    "        'Model Too Large',\n",
    "        'Dataset Too Large',\n",
    "        'VM Selection'\n",
    "    ],\n",
    "    'Solution': [\n",
    "        'Reduce max_samples to 500 or max_seq_length to 128',\n",
    "        'Use max_samples=100 for testing, 1000 for production',\n",
    "        'Use LoRA rank=4 instead of 8 (fewer trainable params)',\n",
    "        'Use max_samples to limit dataset size',\n",
    "        'Always use Standard_E4ds_v4 (32GB RAM), not DS3_v2 (14GB)'\n",
    "    ],\n",
    "    'Config Parameter': [\n",
    "        'data.max_samples, training.max_seq_length',\n",
    "        'data.max_samples',\n",
    "        'lora.r',\n",
    "        'data.max_samples',\n",
    "        'compute_config_cpu.yaml'\n",
    "    ]\n",
    "}\n",
    "\n",
    "df_tips = pd.DataFrame(tips)\n",
    "print(\"Troubleshooting Guide:\")\n",
    "print(\"=\" * 100)\n",
    "print(df_tips.to_string(index=False))\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bec3dd",
   "metadata": {},
   "source": [
    "## 7. Quick Command Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a47b21",
   "metadata": {},
   "source": [
    "### Submit Azure ML Job (Recommended)\n",
    "```bash\n",
    "python jobs/submit_training_job_cpu.py\n",
    "```\n",
    "\n",
    "### Local Training (Testing)\n",
    "```bash\n",
    "# Test with 100 samples\n",
    "python src/train_cpu.py --max_samples 100 --num_epochs 1 --output_dir ./test_output\n",
    "\n",
    "# Production with 1000 samples\n",
    "python src/train_cpu.py --max_samples 1000 --num_epochs 2 --output_dir ./outputs_cpu\n",
    "```\n",
    "\n",
    "### Compare Models After Training\n",
    "```bash\n",
    "python src/compare_models.py --adapter_path ./outputs_cpu/final_model\n",
    "```\n",
    "\n",
    "### View Configuration Files\n",
    "- **CPU Config**: `config/training_config_cpu.yaml`\n",
    "- **CPU Compute**: `config/compute_config_cpu.yaml`\n",
    "- **Training Script**: `src/train_cpu.py`\n",
    "- **Job Submission**: `jobs/submit_training_job_cpu.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831e30f9",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "âœ… **Created CPU-optimized configurations** for Standard_E4ds_v4  \n",
    "âœ… **Training script** (`src/train_cpu.py`) with memory optimizations  \n",
    "âœ… **Job submission** (`jobs/submit_training_job_cpu.py`) for Azure ML  \n",
    "âœ… **Cost-effective**: ~$0.58-$1.16 per training run (1000 samples)  \n",
    "âœ… **No GPU required**: Works with your available VMs  \n",
    "\n",
    "### Next Steps\n",
    "1. Run cell 2 to submit Azure ML training job\n",
    "2. Monitor job in Azure ML Studio\n",
    "3. After training, compare models using `src/compare_models.py`\n",
    "4. Adjust `max_samples` based on your needs (100-1000)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
