# Azure ML Compute Configuration

# Compute Cluster for Training
compute:
  name: "gpu-cluster"
  type: "amlcompute"
  size: "Standard_NC6s_v3"       # 1 x NVIDIA V100 16GB GPU
  min_instances: 0                # Minimum nodes (0 for auto-scale down)
  max_instances: 1                # Maximum nodes
  idle_time_before_scale_down: 300  # Idle time in seconds before scale down
  tier: "dedicated"               # Tier: dedicated or low_priority

# Alternative Compute Sizes (uncomment to use)

# Small GPU (for testing)
# size: "Standard_NC4as_T4_v3"   # 1 x NVIDIA T4 16GB GPU

# Medium GPU (for larger models)
# size: "Standard_NC12s_v3"      # 2 x NVIDIA V100 16GB GPU

# Large GPU (for very large models)
# size: "Standard_NC24s_v3"      # 4 x NVIDIA V100 16GB GPU

# A100 GPU (best performance)
# size: "Standard_NC24ads_A100_v4"  # 1 x NVIDIA A100 80GB GPU

# Compute Instance (for interactive development)
compute_instance:
  name: "dev-instance"
  type: "computeinstance"
  size: "Standard_NC6s_v3"
